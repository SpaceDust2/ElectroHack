"""
üîÆ –ú–æ–¥—É–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
"""

import json
import pandas as pd
import numpy as np
import joblib
from typing import Dict, List, Union
from config import RISK_LEVELS


class FraudPredictor:
    """–ö–ª–∞—Å—Å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""

    def __init__(self, model_path: str):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å –∑–∞–≥—Ä—É–∑–∫–æ–π –º–æ–¥–µ–ª–∏"""
        self.model_data = joblib.load(model_path)
        self.model = self.model_data['model']
        self.feature_names = self.model_data['feature_names']
        self.feature_engineer = self.model_data['feature_engineer']
        self.model_name = self.model_data.get('model_name', 'Unknown')

    def predict_from_file(self, data_path: str) -> List[Dict]:
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–∞"""
        with open(data_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        return self.predict(data)

    def predict(self, data: Union[List[Dict], Dict]) -> List[Dict]:
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤"""
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ø–∏—Å–æ–∫ –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω –æ–¥–∏–Ω –æ–±—ä–µ–∫—Ç
        if isinstance(data, dict):
            data = [data]

        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        df = self.feature_engineer.extract_features(data)

        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        X = df[self.feature_names]
        probabilities = self.model.predict_proba(X)[:, 1]
        predictions = self.model.predict(X)

        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        results = []
        for i, record in enumerate(data):
            fraud_prob = float(probabilities[i])
            is_fraud = bool(predictions[i])

            result = {
                'accountId': record.get('accountId', f'UNKNOWN_{i}'),
                'isCommercial': is_fraud,
                'fraud_probability': fraud_prob,
                'fraud_probability_percent': f"{fraud_prob * 100:.1f}%",
                'risk_level': self._get_risk_level(fraud_prob),
                'interpretation': self._get_interpretation(is_fraud, fraud_prob),
                'patterns': self._analyze_patterns(df.iloc[i])
            }

            results.append(result)

        return results

    def _get_risk_level(self, probability: float) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è —Ä–∏—Å–∫–∞"""
        for level, info in RISK_LEVELS.items():
            if probability >= info['threshold']:
                return level
        return 'MINIMAL'

    def _get_interpretation(self, is_fraud: bool, probability: float) -> str:
        """–¢–µ–∫—Å—Ç–æ–≤–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"""
        if is_fraud:
            if probability > 0.9:
                return "üö® –ú–û–®–ï–ù–ù–ò–ö —Å –æ—á–µ–Ω—å –≤—ã—Å–æ–∫–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é!"
            elif probability > 0.8:
                return "‚ö†Ô∏è –ú–û–®–ï–ù–ù–ò–ö —Å –≤—ã—Å–æ–∫–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é"
            else:
                return "üìç –í–µ—Ä–æ—è—Ç–Ω—ã–π –ú–û–®–ï–ù–ù–ò–ö"
        else:
            if probability < 0.2:
                return "‚úÖ –ß–µ—Å—Ç–Ω—ã–π –∂–∏—Ç–µ–ª—å —Å –≤—ã—Å–æ–∫–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é"
            elif probability < 0.4:
                return "‚úÖ –°–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ —á–µ—Å—Ç–Ω—ã–π –∂–∏—Ç–µ–ª—å"
            else:
                return "‚ùì –¢—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏"

    def _analyze_patterns(self, features: pd.Series) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤ –¥–∞–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–∞"""
        patterns = {
            'consumption_level': self._get_consumption_level(features),
            'seasonality': self._get_seasonality_status(features),
            'stability': self._get_stability_status(features),
            'anomalies': self._get_anomalies(features)
        }

        return patterns

    def _get_consumption_level(self, features: pd.Series) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è"""
        avg_consumption = features.get('avg_consumption', 0)

        if avg_consumption > 500:
            return "–û—á–µ–Ω—å –≤—ã—Å–æ–∫–æ–µ"
        elif avg_consumption > 300:
            return "–í—ã—Å–æ–∫–æ–µ"
        elif avg_consumption > 150:
            return "–°—Ä–µ–¥–Ω–µ–µ"
        else:
            return "–ù–∏–∑–∫–æ–µ"

    def _get_seasonality_status(self, features: pd.Series) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–ª–∏—á–∏—è —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏"""
        ratio = features.get('summer_winter_ratio', 1)

        if 0.8 <= ratio <= 1.2:
            return "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç (–ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ)"
        elif ratio < 0.6:
            return "–í—ã—Ä–∞–∂–µ–Ω–Ω–∞—è (—Ç–∏–ø–∏—á–Ω–æ –¥–ª—è –∂–∏–ª—å—è)"
        else:
            return "–£–º–µ—Ä–µ–Ω–Ω–∞—è"

    def _get_stability_status(self, features: pd.Series) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è"""
        cv = features.get('cv', 0)

        if cv < 0.2:
            return "–û—á–µ–Ω—å —Å—Ç–∞–±–∏–ª—å–Ω–æ–µ (–ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ)"
        elif cv < 0.3:
            return "–°—Ç–∞–±–∏–ª—å–Ω–æ–µ"
        elif cv < 0.5:
            return "–£–º–µ—Ä–µ–Ω–Ω–æ —Å—Ç–∞–±–∏–ª—å–Ω–æ–µ"
        else:
            return "–ù–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ–µ (—Ç–∏–ø–∏—á–Ω–æ –¥–ª—è –∂–∏–ª—å—è)"

    def _get_anomalies(self, features: pd.Series) -> List[str]:
        """–í—ã—è–≤–ª–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π"""
        anomalies = []

        if features.get('high_min_consumption', 0):
            anomalies.append("–í—ã—Å–æ–∫–æ–µ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ")

        if features.get('stable_high_consumption', 0):
            anomalies.append("–°—Ç–∞–±–∏–ª—å–Ω–æ –≤—ã—Å–æ–∫–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ")

        if features.get('no_seasonality', 0) and features.get('avg_consumption', 0) > 300:
            anomalies.append("–ù–µ—Ç —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏ –ø—Ä–∏ –≤—ã—Å–æ–∫–æ–º –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–∏")

        if features.get('zero_consumption_months', 0) == 0 and features.get('months_with_data', 0) >= 10:
            anomalies.append("–ù–µ—Ç –º–µ—Å—è—Ü–µ–≤ —Å –Ω—É–ª–µ–≤—ã–º –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ–º")

        if features.get('consumption_per_resident', 0) > 250:
            anomalies.append("–û—á–µ–Ω—å –≤—ã—Å–æ–∫–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –Ω–∞ –∂–∏—Ç–µ–ª—è")

        return anomalies

    def generate_report(self, results: List[Dict]) -> Dict:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–≤–æ–¥–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º"""
        total = len(results)
        fraudsters = sum(1 for r in results if r['isCommercial'])

        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —É—Ä–æ–≤–Ω—è–º —Ä–∏—Å–∫–∞
        risk_distribution = {}
        for level in RISK_LEVELS.keys():
            count = sum(1 for r in results if r['risk_level'] == level)
            risk_distribution[level] = {
                'count': count,
                'percentage': count / total * 100 if total > 0 else 0
            }

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º
        pattern_stats = {
            'no_seasonality': sum(1 for r in results if '–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç' in r['patterns']['seasonality']),
            'very_stable': sum(1 for r in results if '–û—á–µ–Ω—å —Å—Ç–∞–±–∏–ª—å–Ω–æ–µ' in r['patterns']['stability']),
            'high_consumption': sum(1 for r in results if '–≤—ã—Å–æ–∫–æ–µ' in r['patterns']['consumption_level'].lower())
        }

        report = {
            'summary': {
                'total_analyzed': total,
                'fraudsters_detected': fraudsters,
                'fraud_rate': fraudsters / total * 100 if total > 0 else 0,
                'model_used': self.model_name
            },
            'risk_distribution': risk_distribution,
            'pattern_statistics': pattern_stats,
            'top_suspicious': sorted(results, key=lambda x: x['fraud_probability'], reverse=True)[:10]
        }

        return report

    def export_results(self, results: List[Dict], format: str = 'json', filename: str = 'predictions') -> str:
        """–≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö"""
        if format == 'json':
            filepath = f'{filename}.json'
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)

        elif format == 'csv':
            filepath = f'{filename}.csv'
            # –£–ø—Ä–æ—â–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è CSV
            simplified = []
            for r in results:
                row = {
                    'accountId': r['accountId'],
                    'isCommercial': r['isCommercial'],
                    'fraud_probability': r['fraud_probability'],
                    'risk_level': r['risk_level'],
                    'interpretation': r['interpretation']
                }
                simplified.append(row)

            df = pd.DataFrame(simplified)
            df.to_csv(filepath, index=False, encoding='utf-8')

        else:
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: {format}")

        print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filepath}")
        return filepath


def predict_fraud(data_path: str, model_path: str = 'fraud_detection_model.joblib') -> str:
    """–ë—ã—Å—Ç—Ä–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"""
    predictor = FraudPredictor(model_path)
    results = predictor.predict_from_file(data_path)

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
    report = predictor.generate_report(results)

    print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê")
    print("=" * 50)
    print(f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {report['summary']['total_analyzed']}")
    print(
        f"–í—ã—è–≤–ª–µ–Ω–æ –º–æ—à–µ–Ω–Ω–∏–∫–æ–≤: {report['summary']['fraudsters_detected']} ({report['summary']['fraud_rate']:.1f}%)")
    print(f"\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ä–∏—Å–∫–∞–º:")
    for level, info in report['risk_distribution'].items():
        print(f"  {level}: {info['count']} ({info['percentage']:.1f}%)")

    # –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    predictor.export_results(results, format='json')

    return json.dumps(results, ensure_ascii=False, indent=2)


if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    results = predict_fraud('test_data.json')
