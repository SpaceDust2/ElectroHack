"""
üîÆ –ú–æ–¥—É–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
"""

import json
import pandas as pd
import numpy as np
import joblib
from typing import Dict, List, Union
from config import RISK_LEVELS


class FraudPredictor:
    """–ö–ª–∞—Å—Å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""

    def __init__(self, model_path: str):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å –∑–∞–≥—Ä—É–∑–∫–æ–π –º–æ–¥–µ–ª–∏"""
        self.model_data = joblib.load(model_path)
        self.model = self.model_data['model']
        self.feature_names = self.model_data['feature_names']
        self.feature_engineer = self.model_data['feature_engineer']
        self.model_name = self.model_data.get('model_name', 'Unknown')

    def predict_from_file(self, data_path: str, detailed: bool = False) -> List[Dict]:
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–∞"""
        with open(data_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        return self.predict(data, detailed=detailed)

    def predict(self, data: Union[List[Dict], Dict], detailed: bool = False) -> List[Dict]:
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤
        detailed: –µ—Å–ª–∏ True ‚Äî –ø–æ–¥—Ä–æ–±–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –∏–Ω–∞—á–µ —Ç–æ–ª—å–∫–æ –∏—Å—Ö–æ–¥–Ω—ã–µ –ø–æ–ª—è + isCommercial
        """
        if isinstance(data, dict):
            data = [data]

        df = self.feature_engineer.extract_features(data)
        X = df[self.feature_names]

        # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∞–Ω—Å–∞–º–±–ª—è
        if hasattr(self, 'models'):
            probabilities = np.mean([m.predict_proba(X)[:, 1]
                                    for m in self.models], axis=0)
            predictions = probabilities > 0.5
        else:
            probabilities = self.model.predict_proba(X)[:, 1]
            predictions = self.model.predict(X)

        results = []
        for i, record in enumerate(data):
            fraud_prob = float(probabilities[i])
            is_fraud = bool(predictions[i])

            if not detailed:
                # –ö–æ—Ä–æ—Ç–∫–∏–π —Ñ–æ—Ä–º–∞—Ç: –≤—Å–µ –∏—Å—Ö–æ–¥–Ω—ã–µ –ø–æ–ª—è + isCommercial –ø–æ—Å–ª–µ accountId
                result = {}
                for k, v in record.items():
                    result[k] = v
                    if k == 'accountId':
                        result['isCommercial'] = is_fraud
                # –ï—Å–ª–∏ accountId –Ω–µ –±—ã–ª–æ, –ø—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤–∏–º isCommercial –≤ –Ω–∞—á–∞–ª–æ
                if 'accountId' not in record:
                    result = {'isCommercial': is_fraud, **record}
                results.append(result)
            else:
                # –ü–æ–¥—Ä–æ–±–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç (—Å—Ç–∞—Ä—ã–π)
                result = {
                    'accountId': record.get('accountId', f'UNKNOWN_{i}'),
                    'isCommercial': is_fraud,
                    'fraud_probability': fraud_prob,
                    'fraud_probability_percent': f"{fraud_prob * 100:.1f}%",
                    'risk_level': self._get_risk_level(fraud_prob),
                    'interpretation': self._get_interpretation(is_fraud, fraud_prob),
                    'patterns': self._analyze_patterns(df.iloc[i])
                }
                # –î–æ–±–∞–≤–∏–º –∏—Å—Ö–æ–¥–Ω—ã–µ –ø–æ–ª—è –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
                for k, v in record.items():
                    if k not in result:
                        result[k] = v
                results.append(result)

        return results

    def _get_risk_level(self, probability: float) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è —Ä–∏—Å–∫–∞"""
        for level, info in RISK_LEVELS.items():
            if probability >= info['threshold']:
                return level
        return 'MINIMAL'

    def _get_interpretation(self, is_fraud: bool, probability: float) -> str:
        """–¢–µ–∫—Å—Ç–æ–≤–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"""
        if is_fraud:
            if probability > 0.9:
                return "üö® –ù–ê–†–£–®–ò–¢–ï–õ–¨ —Å –æ—á–µ–Ω—å –≤—ã—Å–æ–∫–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é! –ö–æ–º–º–µ—Ä—á–µ—Å–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–æ–¥ –≤–∏–¥–æ–º –∂–∏–ª–æ–≥–æ"
            elif probability > 0.8:
                return "‚ö†Ô∏è –ù–ê–†–£–®–ò–¢–ï–õ–¨ —Å –≤—ã—Å–æ–∫–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é - —Ç—Ä–µ–±—É–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏"
            else:
                return "üìç –í–µ—Ä–æ—è—Ç–Ω—ã–π –Ω–∞—Ä—É—à–∏—Ç–µ–ª—å - —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞"
        else:
            if probability < 0.2:
                return "‚úÖ –î–æ–±—Ä–æ—Å–æ–≤–µ—Å—Ç–Ω—ã–π –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å - —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –±—ã—Ç–æ–≤–æ–º—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é"
            elif probability < 0.4:
                return "‚úÖ –°–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –¥–æ–±—Ä–æ—Å–æ–≤–µ—Å—Ç–Ω—ã–π –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å"
            else:
                return "‚ùì –ü–æ–≥—Ä–∞–Ω–∏—á–Ω—ã–π —Å–ª—É—á–∞–π - —Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏"

    def _analyze_patterns(self, features: pd.Series) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤ –¥–∞–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–∞"""
        patterns = {
            'consumption_level': self._get_consumption_level(features),
            'seasonality': self._get_seasonality_status(features),
            'stability': self._get_stability_status(features),
            'anomalies': self._get_anomalies(features)
        }

        return patterns

    def _get_consumption_level(self, features: pd.Series) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è"""
        avg_consumption = features.get('avg_consumption', 0)

        if avg_consumption > 500:
            return "–û—á–µ–Ω—å –≤—ã—Å–æ–∫–æ–µ"
        elif avg_consumption > 300:
            return "–í—ã—Å–æ–∫–æ–µ"
        elif avg_consumption > 150:
            return "–°—Ä–µ–¥–Ω–µ–µ"
        else:
            return "–ù–∏–∑–∫–æ–µ"

    def _get_seasonality_status(self, features: pd.Series) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–ª–∏—á–∏—è —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏"""
        ratio = features.get('summer_winter_ratio', 1)

        if 0.8 <= ratio <= 1.2:
            return "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç (–ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ)"
        elif ratio < 0.6:
            return "–í—ã—Ä–∞–∂–µ–Ω–Ω–∞—è (—Ç–∏–ø–∏—á–Ω–æ –¥–ª—è –∂–∏–ª—å—è)"
        else:
            return "–£–º–µ—Ä–µ–Ω–Ω–∞—è"

    def _get_stability_status(self, features: pd.Series) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è"""
        cv = features.get('cv', 0)

        if cv < 0.2:
            return "–û—á–µ–Ω—å —Å—Ç–∞–±–∏–ª—å–Ω–æ–µ (–ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ)"
        elif cv < 0.3:
            return "–°—Ç–∞–±–∏–ª—å–Ω–æ–µ"
        elif cv < 0.5:
            return "–£–º–µ—Ä–µ–Ω–Ω–æ —Å—Ç–∞–±–∏–ª—å–Ω–æ–µ"
        else:
            return "–ù–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ–µ (—Ç–∏–ø–∏—á–Ω–æ –¥–ª—è –∂–∏–ª—å—è)"

    def _get_anomalies(self, features: pd.Series) -> List[str]:
        """–í—ã—è–≤–ª–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π"""
        anomalies = []

        if features.get('high_min_consumption', 0):
            anomalies.append("–í—ã—Å–æ–∫–æ–µ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ")

        if features.get('stable_high_consumption', 0):
            anomalies.append("–°—Ç–∞–±–∏–ª—å–Ω–æ –≤—ã—Å–æ–∫–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ")

        if features.get('no_seasonality', 0) and features.get('avg_consumption', 0) > 300:
            anomalies.append("–ù–µ—Ç —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏ –ø—Ä–∏ –≤—ã—Å–æ–∫–æ–º –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–∏")

        if features.get('zero_consumption_months', 0) == 0 and features.get('months_with_data', 0) >= 10:
            anomalies.append("–ù–µ—Ç –º–µ—Å—è—Ü–µ–≤ —Å –Ω—É–ª–µ–≤—ã–º –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ–º")

        if features.get('consumption_per_resident', 0) > 250:
            anomalies.append("–û—á–µ–Ω—å –≤—ã—Å–æ–∫–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –Ω–∞ –∂–∏—Ç–µ–ª—è")

        return anomalies

    def generate_report(self, results: List[Dict]) -> Dict:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–≤–æ–¥–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º"""
        total = len(results)
        fraudsters = sum(1 for r in results if r['isCommercial'])

        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —É—Ä–æ–≤–Ω—è–º —Ä–∏—Å–∫–∞
        risk_distribution = {}
        for level in RISK_LEVELS.keys():
            count = sum(1 for r in results if r['risk_level'] == level)
            risk_distribution[level] = {
                'count': count,
                'percentage': count / total * 100 if total > 0 else 0
            }

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º
        pattern_stats = {
            'no_seasonality': sum(1 for r in results if '–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç' in r['patterns']['seasonality']),
            'very_stable': sum(1 for r in results if '–û—á–µ–Ω—å —Å—Ç–∞–±–∏–ª—å–Ω–æ–µ' in r['patterns']['stability']),
            'high_consumption': sum(1 for r in results if '–≤—ã—Å–æ–∫–æ–µ' in r['patterns']['consumption_level'].lower())
        }

        report = {
            'summary': {
                'total_analyzed': total,
                'fraudsters_detected': fraudsters,
                'fraud_rate': fraudsters / total * 100 if total > 0 else 0,
                'model_used': self.model_name
            },
            'risk_distribution': risk_distribution,
            'pattern_statistics': pattern_stats,
            'top_suspicious': sorted(results, key=lambda x: x['fraud_probability'], reverse=True)[:10]
        }

        return report

    def export_results(self, results: List[Dict], format: str = 'json', filename: str = 'predictions') -> str:
        """–≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö"""
        if format == 'json':
            filepath = f'{filename}.json'
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)

        elif format == 'csv':
            filepath = f'{filename}.csv'
            # –£–ø—Ä–æ—â–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è CSV
            simplified = []
            for r in results:
                row = {
                    '–õ–∏—Ü–µ–≤–æ–π —Å—á–µ—Ç': r['accountId'],
                    '–ù–∞—Ä—É—à–∏—Ç–µ–ª—å': '–î–∞' if r['isCommercial'] else '–ù–µ—Ç',
                    '–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –Ω–∞—Ä—É—à–µ–Ω–∏—è': f"{r['fraud_probability']:.2%}",
                    '–£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞': r['risk_level'],
                    '–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è': r['interpretation']
                }
                simplified.append(row)

            df = pd.DataFrame(simplified)
            df.to_csv(filepath, index=False, encoding='utf-8')

        else:
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: {format}")

        print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filepath}")
        return filepath


def predict_fraud(data_path: str, model_path: str = 'fraud_detection_model.joblib', detailed: bool = False) -> str:
    """–ë—ã—Å—Ç—Ä–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"""
    predictor = FraudPredictor(model_path)
    results = predictor.predict_from_file(data_path, detailed=detailed)

    if detailed:
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
        report = predictor.generate_report(results)
        print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê")
        print("=" * 50)
        print(f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {report['summary']['total_analyzed']}")
        print(
            f"–í—ã—è–≤–ª–µ–Ω–æ –Ω–∞—Ä—É—à–∏—Ç–µ–ª–µ–π: {report['summary']['fraudsters_detected']} ({report['summary']['fraud_rate']:.1f}%)")
        print(f"\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ä–∏—Å–∫–∞–º:")
        for level, info in report['risk_distribution'].items():
            print(f"  {level}: {info['count']} ({info['percentage']:.1f}%)")
        # –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        predictor.export_results(results, format='json')
    else:
        print(f"\n‚úÖ –ö–æ—Ä–æ—Ç–∫–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {len(results)} –∑–∞–ø–∏—Å–µ–π")
        predictor.export_results(
            results, format='json', filename='predictions_short')

    return json.dumps(results, ensure_ascii=False, indent=2)


if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    # –ö–æ—Ä–æ—Ç–∫–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:
    results = predict_fraud('test_data.json', detailed=False)
    # –ü–æ–¥—Ä–æ–±–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:
    # results = predict_fraud('test_data.json', detailed=True)
