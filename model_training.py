"""
ü§ñ –ú–æ–¥—É–ª—å –æ–±—É—á–µ–Ω–∏—è ML –º–æ–¥–µ–ª–µ–π
"""

from feature_engineering import FeatureEngineer
from config import MODEL_PARAMS
import json
import numpy as np
import pandas as pd
from sklearn.model_selection import StratifiedKFold, cross_val_score
from sklearn.metrics import roc_auc_score, accuracy_score, classification_report
from sklearn.ensemble import RandomForestClassifier
from catboost import CatBoostClassifier
from xgboost import XGBClassifier
import joblib
from typing import Dict, List, Tuple, Any
import warnings
warnings.filterwarnings('ignore')


class ModelTrainer:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–µ–π"""

    def __init__(self, use_gpu: bool = True):
        self.use_gpu = use_gpu
        self.models = self._init_models()
        self.feature_engineer = FeatureEngineer()
        self.best_model = None
        self.best_score = 0
        self.results = {}

    def _init_models(self) -> Dict[str, Any]:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞"""
        models = {}

        # CatBoost
        catboost_params = MODEL_PARAMS['catboost'].copy()
        if not self.use_gpu:
            catboost_params['task_type'] = 'CPU'
        models['CatBoost'] = CatBoostClassifier(**catboost_params)

        # XGBoost
        xgboost_params = MODEL_PARAMS['xgboost'].copy()
        if not self.use_gpu:
            xgboost_params['tree_method'] = 'hist'
        models['XGBoost'] = XGBClassifier(**xgboost_params)

        # Random Forest
        models['RandomForest'] = RandomForestClassifier(
            **MODEL_PARAMS['random_forest'])

        return models

    def load_data(self, train_path: str, test_path: str = None) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
        print("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")

        with open(train_path, 'r', encoding='utf-8') as f:
            train_data = json.load(f)

        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        print("üîß Feature engineering...")
        train_df = self.feature_engineer.extract_features(train_data)

        test_df = None
        if test_path:
            with open(test_path, 'r', encoding='utf-8') as f:
                test_data = json.load(f)
            test_df = self.feature_engineer.extract_features(test_data)

        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {len(train_df)} train")
        if test_df is not None:
            print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {len(test_df)} test")
        print(f"‚úÖ –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(self.feature_engineer.feature_names)}")

        return train_df, test_df

    def train_models(self, train_df: pd.DataFrame, cv_folds: int = 5) -> Dict[str, Dict]:
        """–û–±—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π —Å –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
        print("\nüöÄ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π...")

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        X = train_df[self.feature_engineer.feature_names]
        y = train_df['isCommercial']

        # –°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
        skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)

        for model_name, model in self.models.items():
            print(f"\nüìä –û–±—É—á–µ–Ω–∏–µ {model_name}...")

            # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
            cv_scores = cross_val_score(
                model, X, y, cv=skf, scoring='roc_auc', n_jobs=-1
            )

            # –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –ø–æ–ª–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ
            model.fit(X, y)

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            self.results[model_name] = {
                'model': model,
                'cv_scores': cv_scores,
                'cv_mean': cv_scores.mean(),
                'cv_std': cv_scores.std(),
                'feature_names': self.feature_engineer.feature_names
            }

            print(f"  AUC: {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}")

            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
            if cv_scores.mean() > self.best_score:
                self.best_score = cv_scores.mean()
                self.best_model = model_name

        print(
            f"\nüèÜ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {self.best_model} (AUC: {self.best_score:.4f})")

        return self.results

    def evaluate_on_test(self, test_df: pd.DataFrame) -> Dict[str, Dict]:
        """–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ"""
        if not self.results:
            raise ValueError("–°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª–∏!")

        print("\nüìè –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ...")

        X_test = test_df[self.feature_engineer.feature_names]
        y_test = test_df['isCommercial']

        test_results = {}

        for model_name, model_info in self.results.items():
            model = model_info['model']

            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            y_pred_proba = model.predict_proba(X_test)[:, 1]
            y_pred = model.predict(X_test)

            # –ú–µ—Ç—Ä–∏–∫–∏
            auc = roc_auc_score(y_test, y_pred_proba)
            accuracy = accuracy_score(y_test, y_pred)

            test_results[model_name] = {
                'auc': auc,
                'accuracy': accuracy,
                'predictions': y_pred,
                'probabilities': y_pred_proba
            }

            print(f"\n{model_name}:")
            print(f"  AUC: {auc:.4f}")
            print(f"  Accuracy: {accuracy:.4f}")

        return test_results

    def get_feature_importance(self, model_name: str = None) -> pd.DataFrame:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        if model_name is None:
            model_name = self.best_model

        if model_name not in self.results:
            raise ValueError(f"–ú–æ–¥–µ–ª—å {model_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")

        model = self.results[model_name]['model']
        feature_names = self.results[model_name]['feature_names']

        # –ü–æ–ª—É—á–µ–Ω–∏–µ –≤–∞–∂–Ω–æ—Å—Ç–∏
        if hasattr(model, 'feature_importances_'):
            importances = model.feature_importances_
        elif hasattr(model, 'get_feature_importance'):
            importances = model.get_feature_importance()
        else:
            return pd.DataFrame()

        # –°–æ–∑–¥–∞–Ω–∏–µ DataFrame
        importance_df = pd.DataFrame({
            'feature': feature_names,
            'importance': importances
        }).sort_values('importance', ascending=False)

        return importance_df

    def save_model(self, model_name: str = None, filename: str = 'model.joblib') -> str:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        if model_name is None:
            model_name = self.best_model

        if model_name not in self.results:
            raise ValueError(f"–ú–æ–¥–µ–ª—å {model_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ–±—ä–µ–∫—Ç–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        model_data = {
            'model': self.results[model_name]['model'],
            'feature_names': self.results[model_name]['feature_names'],
            'model_name': model_name,
            'cv_score': self.results[model_name]['cv_mean'],
            'feature_engineer': self.feature_engineer
        }

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        joblib.dump(model_data, filename)
        print(f"‚úÖ –ú–æ–¥–µ–ª—å {model_name} —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {filename}")

        return filename

    def generate_training_report(self) -> Dict:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ–± –æ–±—É—á–µ–Ω–∏–∏"""
        report = {
            'best_model': self.best_model,
            'best_score': float(self.best_score),
            'total_features': len(self.feature_engineer.feature_names),
            'models_results': {}
        }

        for model_name, model_info in self.results.items():
            report['models_results'][model_name] = {
                'cv_mean_auc': float(model_info['cv_mean']),
                'cv_std_auc': float(model_info['cv_std']),
                'cv_scores': model_info['cv_scores'].tolist()
            }

        # –¢–æ–ø –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        if self.best_model:
            importance_df = self.get_feature_importance()
            if not importance_df.empty:
                report['top_features'] = importance_df.head(
                    10).to_dict('records')

        return report


def train_pipeline(train_path: str, test_path: str = None,
                   model_filename: str = 'fraud_model.joblib',
                   use_gpu: bool = True) -> Dict:
    """–ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –æ–±—É—á–µ–Ω–∏—è"""

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    trainer = ModelTrainer(use_gpu=use_gpu)

    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    train_df, test_df = trainer.load_data(train_path, test_path)

    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    trainer.train_models(train_df)

    # –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–µ
    test_results = None
    if test_df is not None:
        test_results = trainer.evaluate_on_test(test_df)

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    trainer.save_model(filename=model_filename)

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
    report = trainer.generate_training_report()
    if test_results:
        report['test_results'] = {
            name: {
                'auc': float(results['auc']),
                'accuracy': float(results['accuracy'])
            }
            for name, results in test_results.items()
        }

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
    with open('training_report.json', 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)

    print("\n‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    print(f"üìä –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ training_report.json")

    return report


if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è
    report = train_pipeline(
        train_path='data/dataset_train.json',
        test_path='data/dataset_test.json',
        model_filename='fraud_detection_model.joblib',
        use_gpu=True
    )
